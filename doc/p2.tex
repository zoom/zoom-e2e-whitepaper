\section{Phase II: Identity}

In Phase II, we will introduce the concept of \textit{identity} and use it to guarantee that only
authorized participants will be able to join a meeting. End-to-end encryption is only as secure as
the ends: if Alice thinks she is talking to her coworkers, but instead her competitors are
participating in the meeting or there is a meddler-in-the-middle, encryption will not be sufficient to protect her. Zoom will give
meeting leaders more helpful and trustworthy information to evaluate join requests and kick
questionable users out of a meeting.

This section details changes to how we define and represent a user's identity to the people they
interact with on Zoom, as well as how we enforce that these identities are consistent over time and
cannot be tampered with.

\subsection{Identity at Zoom Before Phase II}

Zoom organizes its users into accounts. Accounts can be held by individual people, businesses or
institutions, and they consist of one or more users: if Example Corporation uses Zoom, then each
Example Corporation employee would be a Zoom user belonging to the Example Corporation account. Each
user can have more than one device (e.g., a computer or a phone) which they can use to join meetings
and use Zoom services.

Each account is part of a cloud infrastructure that hosts the data relating to the account and its
users, such as email addresses and login information. Some Zoom users are in the Zoom commercial
cloud; there is also a Zoom government cloud for U.S. government employees and contractors, as well
as separate white-labeled private Zoom instances, each with their own cloud. Users can join meetings
that are hosted in a different cloud from their own.

Zoom users authenticate to Zoom in a variety of ways. Users can log in using their email address and
a password, or via an OAuth or SAML-based flow with an external Identity Provider (\idp) that has
been set up for their account. In all of these cases, an email address is
used as a unique user identifier. If the account settings allow it, users can change their email
address or authentication method.

Individuals do not need to sign in as a Zoom user in order to join a meeting, unless it is
configured otherwise. They can join a meeting by clicking a link or by entering the meeting ID and
password in the app.

At the time of writing, Zoom gives the host and meeting participants limited information about the
identities of the other participants. Aside from the audio and video streams that each individual
participant might share, the participants are identified through a profile picture and
a display name. This display name can be freely chosen and modified over the course of
a meeting (both by the user and by the meeting host) as well as across different meetings. In some
cases, account admins can restrict their users to an approved display name, but this is enforced by
the Zoom servers and cannot be verified by clients.

Zoom provides some mechanisms to enforce access control in a meeting, such as meeting passwords, the
waiting room feature, and the ability to restrict the meeting to users in the host's account or
users whose emails have a specific domain name. These features are enforced by the Zoom servers, so
they can be circumvented if the server is compromised. They also do not prevent one member of an
account from impersonating another member of the same account, and they may not give the host
enough information to make a decision about whether to admit an attendee from the waiting room.

\subsection{Changes in Phase II}

The identity of a Zoom user will consist of two components. The first component is a set of
human-readable identifiers unique to each user and the account they belong to. This allows users to
be identified by displaying their email addresses and information about their Zoom accounts to their
meeting partners. Second, each user's identity will include the set of devices (and their
cryptographic keys) that are controlled by that user. We describe a device model which lets us reason
about how a user's devices and keys change over time, and helps us formalize the concept of trust
between devices. The device model includes a mechanism to securely share secret keys between all of
a user's devices, which can be used to sync encrypted data. To allow a user's devices to securely
communicate with each other, each device will now generate an additional keypair for encryption at
the same time it generates its signing keypair as described in Section~\ref{sec:keymanage}.

The components of a user's identity can change over time, and it is important to keep track of such
changes so that they are auditable. For this purpose, we will introduce a data structure which we
call a signed hashchain, or \textit{sigchain}.

Devices will remember the users and devices they've seen in meetings and will provide warnings to
users when they meet with a device they haven't met with before, in order to prevent certain kinds
of impersonation attacks.

We also introduce an extension of the OpenID Connect protocol that {\idp}s can use to make claims
about a user's identity that can be verified by other users. If an account's \idp supports this
protocol, even Zoom insiders cannot impersonate a user in the account, unless the \idp or one of
that user's devices is also compromised.

Finally, there will be several accompanying changes to the user interface, including a device
approval process.

\subsection{Displaying Identity}
\label{subsec:displayid}

This section describes changes to how we display the identity of a Zoom user to others. In Phase II,
these changes will mainly pertain to Zoom meetings, but they will eventually be expanded to other
Zoom services such as Zoom Chat.

Because cryptographic keys are not easy to read, compare, or keep track of, we will only show
human-readable identifiers in the user interface. A user's set of identifiers consists of three
components:

\begin{enumerate}
\item A Cloud Identifier, which represents the cloud infrastructure a user's
    information is hosted on (omitted if the user is on the Zoom commercial cloud)
\item An Account
    Domain Name (ADN), which identifies the account that the user is part of, where applicable
\item
    An email address, which can be used to distinguish individual users within the account
\end{enumerate}

In Phase II, only users in accounts with identity providers will have identifiers shown next to
their display name in meetings. In Phase III, we'll extend this functionality for users in accounts
without an identity provider. Here are a few examples of how a user's identifiers would be
displayed in-meeting:

\begin{multicols}{2}
John Smith \\
\texttt{example.com} (\texttt{jsmith@example.net})

\columnbreak

The display name, ``John Smith," is freely chosen and not authenticated. \texttt{example.com} is the
ADN\@. Note that the email domain, \texttt{example.net}, can differ from the ADN\@.
\end{multicols}

\begin{multicols}{2}
Lucy Lee \\
\texttt{example.org} (\texttt{lucy.lee@example.org}) \\ \textbf{GOV}

\columnbreak

Since the \texttt{example.org} company works with the US government, their identities and keys
are hosted on the separate Zoom Government Cloud, and this is noted in the UI.
\end{multicols}

\begin{multicols}{2}
Anna Smith \\
\texttt{example.com}

\columnbreak

Anna might decide not to disclose her email address but still be identified as a member of the
\texttt{example.com} account. In this case, although the user's email address would not be
revealed, their devices' long-term cryptographic public keys could be leveraged by a determined
attacker to ascertain when the same device has been used across different meetings, even when
the display name is altered.
\end{multicols}

\begin{multicols}{2}
Richard Roe

\columnbreak

As in Phase I, users can join meetings as guests and display no identifying information to
other users. Since they generate fresh long-term keys for each meeting, the aforementioned tracing
attack is not possible.
\end{multicols}

\begin{multicols}{2}
Mike Doe \\
(\texttt{mike.doe@example.com})

\columnbreak

In Phase III, we will be able to show email addresses for users like Mike whose accounts don't have
an ADN or an \idp.
\end{multicols}

\subsubsection{Identifying Accounts}

Accounts on Zoom can be optionally identified using a domain name, which we will call the Account
Domain Name (ADN). Domain names make good identifiers because they are unique (while for example two
companies with the same name might exist in two countries), and many users are already familiar with
them. We will allow internationalized domain names (IDNs) to be used as ADNs, but to prevent
homograph attacks, the UI will show the Punycode representation by default and the rendered domain
name only on mouse hover.

An account admin may choose one of the account’s existing Associated Domains as the ADN, or Zoom can
provide a new dedicated subdomain. Associated Domains is an existing Zoom feature where a Zoom
account can be associated with multiple domain names. To do so, the account admin has to prove
ownership of the domain name to Zoom, e.g., by adding a specific DNS record, adding a header tag to
the home page or by hosting a file at a specific location on the domain.

Only a single account at a time can use a domain name as their ADN, and account admins are allowed
to change their ADN if needed.

\subsubsection{Identifying Users}

Zoom users will also be identified with email addresses. Most users already have an email address
associated with their account; moreover emails (unlike names) are unique, and they sometimes
represent people better than the legal name held in a company’s HR system.

Users will be able to change the email associated with their account. When a user Alice changes
their email from \texttt{support@example.com} to \texttt{alice@example.com}, for example, other
users that interacted with Alice are not notified of this change. However, if a new user Bob takes
over Alice’s old email \texttt{support@example.com} and associates it with his existing account,
then people who used to meet with \texttt{support@example.com} when it was associated with Alice’s
account will get a prompt explaining that \texttt{support@example.com} is now associated with a new
user. These notifications are supported by the \hyperref[subsec:contactsync]{Contact Sync} feature.

In Phase II, email addresses are treated as secondary to the account domain name, which allows
account admins to delegate to a single identity provider the ability to attest to the identity of
all users within their account, regardless of the email provider they use. In Phase III, we will
also guarantee that each email is associated with a single Zoom user at a time, so that even
accounts without an ADN or IDP can have identity guarantees.

\subsection{Multi-Device Support}
\label{p2:multidev}

Zoom users often have several devices that they use Zoom on: their work computer, personal computer,
mobile phone, and so on. In Phase I, each of these devices stores long-term signing keys (called
\textit{device keys}) which it uses to authenticate key exchanges at the start of video meetings.
In Phase II, we will formalize the set of a user's device keys as well as the ways this set can
change over time, a crucial step towards achieving the goal of linking a user's identifiers with
their device keys.

Users have three main operations to change their set of valid devices:
\begin{enumerate}
\item $\deviceadd{}$, which adds a new device to the set. The new device generates a new long term
    signing key, which will be used to join meetings and to sign statements about the set, and
    an encryption key, which can be used to communicate with other devices.
\item $\devicerevoke{}$, which revokes the validity of a previously-added device. Revoked devices
    are still recorded as part of the set for auditing purposes, but their keys cannot be used to
    join meetings or sign new statements.
\item $\batchapprove{}$, which indicates that an existing device considers all devices added to the
    set until this $\batchapprove{}$ event legitimate and trustworthy. This operation is signed by
    the approving device’s key.
\end{enumerate}

Ensuring that each user has a single set of devices which is consistent over time serves several
purposes. For the user themselves, it ensures that all of their devices know about each other, so
they can be notified when a new device gets added and quickly react if their user account has been
compromised.

A user’s set of devices is also of interest to their meeting partners, because not all devices
associated with a user may be trusted equally. If Bob is in a meeting with Alice's work computer
today, he can trust the connection (i.e., that there is no MitM) by either checking the
security code or by noticing that Alice’s public key is the same as was used in all past meetings
Bob had with Alice. This way, Bob only has to trust that there was no MitM the first time the
connection was established, and from that assumption deduce that all meetings where Alice has the
same public key are also secure. This assumption is commonly referred to as Trust-On-First-Use
(TOFU). If tomorrow, Bob meets with Alice's new mobile phone, Bob might not trust its key as much as
her work computer’s: a malicious server could have added it, or a hacker could have stolen Alice's
Zoom password. It'd be unfortunate if they had to recheck the security code. By performing
a $\batchapprove{}$ operation from her work computer, Alice can indicate that all of her other
devices are trusted, so Bob (who trusts the public key on Alice’s work laptop) can use the signed
$\batchapprove{}$ statement to extend this trust to Alice's new mobile phone’s key.

$\batchapprove{}$ links induce a trust graph over a user's set of devices, where each device
represents a node and each $\batchapprove{}$ adds an edge from the device performing the approval to
all non-revoked devices introduced after that device. We call each connected component in this graph
an approval class, and we assume devices in the same approval class trust each other. When a Zoom user
provisions a new device, they'll have access to their complete device list and so will be able to
revoke any that are unrecognized, lost, or stolen. Because of this, we assume that later devices
implicitly trust the validity of earlier ones.

Consider the following scenario:
\begin{enumerate}
\item Bob provisions Device $\zdev{a}$
\item Bob provisions Device $\zdev{b}$
\item Bob provisions Device $\zdev{c}$
\end{enumerate}

Bob's graph is disconnected: he has 3 separate devices and 3 different approval classes. $\zdev{c}$
does implicitly trust $\zdev{b}$, but we don't consider them part of the same approval class as the
trust is not mutual.

\begin{enumerate}
  \setcounter{enumi}{3}
\item Bob logs onto $\zdev{b}$ and performs a $\batchapprove{}$
\end{enumerate}

This operation partially connects Bob's trust graph. $\zdev{b}$ trusts $\zdev{c}$ (the device
provisioned after $\zdev{b}$). Now, there are only two approval classes: one with $\zdev{a}$ and one
with $\zdev{b}$ and $\zdev{c}$.

\begin{enumerate}
  \setcounter{enumi}{4}
\item Bob provisions Device $\zdev{d}$
\item Bob logs onto $\zdev{c}$ and performs a $\batchapprove{}$
\end{enumerate}

Now, $\zdev{c}$ trusts $\zdev{d}$. Because $\zdev{b}$ already trusted $\zdev{c}$, we know that
$\zdev{b}$ trusts $\zdev{d}$ as well, even though it never made this claim explicitly.

\begin{enumerate}
  \setcounter{enumi}{6}
\item A malicious server provisions Device $\zdev{e}$ in order to impersonate Bob
\item Bob logs onto $\zdev{a}$, revokes $\zdev{e}$ since it's unrecognized, and performs a
    $\batchapprove{}$
\end{enumerate}

Having all of Bob's devices know about each other allows Bob to take action if his account is
compromised. After he revokes $\zdev{e}$, all of Bob's devices, as well as his meeting partners, now
know not to trust statements signed by $\zdev{e}$'s device key. Figure~\ref{fig:devices} summarizes
Bob's trust graph after these steps.

\begin{figure}
\centering
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.4cm,semithick]
  \node[shape=circle,fill=blue,text=white,draw=none]         (A)              {$\zdev{a}$};
  \node[shape=circle,fill=blue,text=white,draw=none]         (B) [right of=A] {$\zdev{b}$};
  \node[shape=circle,fill=blue,text=white,draw=none]         (C) [right of=B] {$\zdev{c}$};
  \node[shape=circle,fill=blue,text=white,draw=none]         (D) [right of=C] {$\zdev{d}$};
  \node[shape=circle,fill=red,text=white,draw=none]          (E) [right of=D] {$\zdev{e}$};

  \path (A) edge                node {step 8} (B)
            edge [bend left]    node {step 8} (C)
            edge [bend right]   node {step 8} (D)
        (B) edge                node {step 4} (C)
        (C) edge                node {step 6} (D);
\end{tikzpicture}
\caption{Device approval graph, where nodes are devices and edges are approvals.}
\label{fig:devices}
\end{figure}

\subsubsection{Per-User Keys}

One application of the trust graph is to facilitate per-user keys (PUKs): a set of keys shared
between all of a user's devices, rotated on device addition or revocation. PUKs include both symmetric keys and asymmetric encryption keys.

Symmetric PUKs can facilitate syncing encrypted data between a user's devices. Devices
use the latest per-user key to encrypt all content, but the previous per-user keys are still useful
for decrypting older data. In the above example, if $\zdev{f}$ is provisioned, it doesn't yet have
access to older PUKs; only the one it just created. But if an older device performs a
$\batchapprove{}$ that includes $\zdev{f}$, it will also encrypt all the PUKs it knows about for the
devices it's approving, which means $\zdev{f}$ can now decrypt data encrypted with keys created before $\zdev{f}$ was
introduced.

Asymmetric encryption PUKs can be used to encrypt data for other users. If Alice encrypts a message for Bob using his asymmetric PUK, Bob can still read the message on devices added afterwards, as long as the device has been approved by an earlier one.

In each $\deviceadd{}$ or $\devicerevoke{}$ operation, devices generate a new seed and encrypt the
seed for each previous unrevoked device using its device keys: devices implicitly trust all older
devices (otherwise, they would revoke them). Each seed is associated with a number called a
\textit{PUK generation} that starts at 1 and increments every time the seed rotates. Note that all devices within an approval class share the same set of PUK seeds.

To generate a set of
PUKs, devices:

\begin{enumerate}
\item
Generate a new 32-byte secret seed
\item
Use HKDF on the seed to generate two different 32-byte keys:
\begin{enumerate}
\item
private X25519, context \texttt{”Zoombase-2-ClientOnly-KDF-PerUserX25519”}
\item
symmetric, context \texttt{”Zoombase-2-ClientOnly-KDF-PerUserSymmetricKey”}
\end{enumerate}
\end{enumerate}

See Appendix~\ref{appendix:multidev} for a deeper analysis of multi-device configurations and the
guarantees we can achieve given these rules.

\subsection{Consistent Identities With Sigchains}
\label{subsec:sigchains}

Both accounts and users have states that change over time. An account can change its
identity provider or its ADN, and a user can change their email address or add and remove
devices.

We need to keep track of states that change over time in a way that is auditable.
To do so, we describe the sequence of changes in a data structure called a signed
hashchain, or sigchain.

Once a client learns of a sigchain, the only changes to this chain that will be considered valid are
extensions of the sequence. Since changes cannot be ``forgotten,” the Zoom server cannot rewrite
history.

Still, this model doesn't force the Zoom server to be consistent across different devices it talks to.
In Phase III, we will add a transparency layer to ensure that the Zoom server must present the same
information about sigchains to all users.

\subsubsection{Sigchains}

A sigchain is a sequence of statements (called \textit{links}), where each link includes a
collision-resistant hash of the previous link. These links can be thought of as state transitions
which modify an object (the sigchain state). For a user sigchain, the sigchain state would contain
the list of active devices, list of revoked devices, the trust graph, and the list of email
addresses and accounts historically associated with the user.

In order to accept a transition as valid, clients will check that it satisfies several conditions,
including that:

\begin{enumerate}
\item The link is of a known type.
\item The link has the correct fields for that type.
\item The transition is admissible given the current state.
\item The link correctly includes the hash of the previous link.
\item Some links require cryptographic signatures by the devices authorizing the transition
    to be considered valid. In these cases, the signatures are encoded as part of the links to
    compute link hashes.
\end{enumerate}

Examples of admissibility rules for a user sigchain include that a device can only be revoked if it
was active in the previous state, and that signatures over revocation links must be by a device that
was active in the previous state.

Since each of the links in a sigchain contains a hash of the previous link, the hash of the last
link is a compact commitment to the entire sigchain state. Each sigchain link
also contains an incrementing sequence number. We refer to an object consisting of the sigchain type, the
last link’s sequence number, and the last link's hash as the \textit{sigchain tail}:

\begin{Verbatim}
{
  "sigchainType": "User",
  "lastSequenceNumber": 15,
  "lastLinkHash": "484ad7..."
}
\end{Verbatim}

When clients want to update their view of a sigchain from the server, they can just query for the
new links and ensure that the first new link contains a previous hash matching the cached tail.

Note that the examples of objects in this document are encoded in JSON and simplified for
ease of exposition. The actual implementation may use different application
encodings and data structures.

Different applications require different levels of access to sigchains. For example, although a user
should be able to fully audit the history of past email addresses stored in their sigchain, meeting
participants might only need to see the most recent one to display it in the UI\@. For this reason,
rather than being directly encoded, sensitive information on a sigchain link is stored as a
commitment: rather than \texttt{alice@example.com}, a sigchain link could contain
$$\mathsf{COMMIT}(\texttt{alice@example.com}) =
    \mathsf{HMAC}(\mathsf{randomKey}, \texttt{alice@example.com}).$$
The server gives all users the entire sigchain link so that they can check that its signatures and
hashes are valid, but only Alice’s devices will receive the plaintext email addresses and 32-byte
random keys corresponding to previous email addresses. \textsf{COMMIT} can also be used to
selectively delete parts of links such as device names: a server can throw away the random HMAC key
as well as the plaintext data, and the signature over the link will still verify.

\subsubsection{Overview of Sigchain Types}

Zoom devices, users, and accounts are each internally identified by unique immutable identifiers
called \deviceid, \userID and \accountID respectively. Each device, user, and account is also
associated with more user-friendly (but mutable) identifiers: respectively, device names, email
addresses, and ADNs.

Representing these different components and their relationships requires different types of
sigchains:

\begin{enumerate}
\item User sigchains store, for each \userID, information related to that user’s identity, such as
    the user’s email address, \accountID, and the set of their devices and their trust
    relationships.
\item Email sigchains store, for each email address, the associated \userID.
\item Account sigchains store, for each \accountID, both the ADN and identity provider associated with
    the account.
\item ADN sigchains keep track, for each domain name, the \accountID to which the domain is
    associated.
\item Membership sigchains keep track, for each \accountID, the {\userID}s within the account.
\end{enumerate}

Note that some of the information stored on these sigchains is redundant: for example, a mapping
between an email and the corresponding \userID is recorded both in a user sigchain and in an email
sigchain. This is necessary so that the server cannot claim that two separate {\userID}s are
associated with the same email address at the same time. Accordingly, some operations will cause
multiple chains to be updated at the same time.

As detailed earlier, every Zoom user is part of an account. For efficiency reasons, if this account
only has a single user and doesn't have an ADN, then that user's sigchain will not mention their
\accountID, and there will be no corresponding account or membership sigchains until the
account either gets another user or an ADN.

\subsubsection{User Sigchains}

User sigchains record changes to a user’s identity. There are several types of user sigchain links,
each representing a different way to change a user's identity.

\paragraph{EmailChange.} As mentioned in Section~\ref{subsec:displayid}, users can set and change the
email addresses that will be displayed in the meeting UI\@. Two users can switch email addresses,
but the server will prove that two users do not have the same email address at the same time. An
\textsf{EmailChange} link will have the following fields:


\begin{Verbatim}
{
  "sigchainType": "User",
  "linkType": "EmailChange",
  "sequenceNumber": 10,
  "prev": "484ad7...",
  "cloudName": "commercial",

  "userID": "ebc0d2...",

  "emailChange": COMMIT({
    "email": "alice@example.com",
    "emailChainSequenceNumber": 5
  })
}
\end{Verbatim}

The first six fields are common to every sigchain link. \textsf{sequenceNumber} is an incrementing counter that starts from 1 for the first link, \textsf{prev} is the (canonical) hash of the previous link in the chain (in this case,
the one with sequence number 9), and \textsf{cloudName}
specifies which cloud the sigchain belongs to.

Every user sigchain link also specifies the \userID.

Here, the \textsf{email} field specifies the new email address to be associated with this user,
which supersedes any previous email. Every time an \textsf{EmailChange} link associates this user
with a new email, the email sigchain for that email address is also extended with a corresponding
\textsf{UserIDChange} link referring to this user’s \userID, and the sequence number of that link is
reported in this link as \textsf{emailChainSequenceNumber}.

Because the Zoom website can be used to change one's email address, \textsf{EmailChange} links do
not have any signatures (i.e., they can be inserted into sigchains by the Zoom server).

\paragraph{AccountChange.} Users can also transfer between accounts, similarly to how they can
switch emails.

\begin{Verbatim}
{
  "sigchainType": "User",
  "linkType": "AccountChange",
  ...
  "accountChange": COMMIT({
    "accountID": "c2d8aa...",
    "membershipChainSequenceNumber": 12,
    "additionIndex": 5
  })
}
\end{Verbatim}

Since multiple users can be added to a membership sigchain in a single link,
\textsf{additionIndex} specifies the corresponding position in that link. If a user
is removed from an account, the \textsf{accountChange} section specifies \accountID
\texttt{null} and the other two fields are omitted.

Since Zoom servers are allowed to move users between accounts, \textsf{AccountChange} links do
not have any signatures. Users will be notified when their account changes.

\paragraph{DeviceAdd.} A device addition link specifies the long-term public device keys for the new
device and a human-readable name:

\begin{Verbatim}
{
  "sigchainType": "User",
  "linkType": "DeviceAdd",
  ...
  "deviceID": "ebc0d2...",
  "deviceName": COMMIT({
    "name": "Alice's Work Smartphone",
    "version": 1
   }),
  "ed25519PublicKey": "ce8564...",
  "x25519PublicKey": "ad7913...",

  "perUserX25519PublicKey": "c2cce1...",

  "emailChange": ...,
  "accountChange": ...,

  "revokeDeviceIDs": [
     "ac98ad...",
     ...
  ]
}
\end{Verbatim}

This link specifies a device identifier (unique among the devices associated with this user), a
signing public key, an encryption public key, as well as a device name. Note that the device name is
hidden by a commitment, because users other than the owner of the chain do not need to see it. In
order to support reusing names, the device name includes an incrementing version component which
will be visible in the user interface. Device names allow the user to have a human-readable,
unambiguous way to distinguish their devices.

The link also specifies the new per-user key public key. The encryptions of the new PUK seeds for
older devices are not represented within the sigchain link, but are sent separately to the server,
which propagates them to the older devices.

If the $\deviceadd{}$ link is the first link in a user's sigchain, it might also include
\textsf{emailChange} and \textsf{accountChange} fields, which convey similar information as the
corresponding sigchain links. Including these fields here allows us to reduce the overall number of
sigchain links.

The user can also decide to revoke any undesired devices at the same time they are adding a new device,
which justifies our claim that later devices should trust the validity of earlier (unrevoked) ones.

To ensure that users know the corresponding device private key, each $\deviceadd{}$ link requires a
signature by \textsf{ed25519PublicKey}.

\paragraph{DeviceRename.} Users can change their device names if desired. This change is signed with
the device's public key.

\paragraph{DeviceRevoke.} When a device is stolen, lost, or no longer used for Zoom, the user should
revoke it. If one of the user’s valid devices performs the revocation, it will also rotate the PUKs
and sign this link to guarantee integrity of the new key. If instead the revocation is done through
the Zoom website, the PUK cannot be rotated and no signature is made.

\paragraph{DeviceKeyRotate.} If a user suspects their device was temporarily compromised, or if
they have institutional key rotation policies, they might want to rotate their device key and PUKs.
This operation keeps the same \deviceid but chooses new signing and encryption keys, as well as a
new set of PUKs. After others see this link, they will only accept signatures and ciphertexts from
the new public keys for this device.

This link is signed by the device's previous public key in addition to the new key.

\paragraph{BatchApprove.} A $\batchapprove{}$ link lets a device indicate that it trusts the
validity of all devices created after that device until the point in the sigchain where the
$\batchapprove{}$ link appears. To reduce the number of sigchain links, the user can also specify a
list of devices to revoke within this link. The link can specify a new set of PUKs, and this is
required if any devices are being revoked.

This link is signed by the approving device, and can be used to construct a trust graph as described
in Section~\ref{p2:multidev}.

\paragraph{PerUserKeyRotate.} If a device notices that the last PUK was generated by a device
revoking itself, or there was a revocation from the website after the last PUK was generated, the
device will perform another PUK rotation using a $\peruserkeyrotate{}$ link. This guarantees that
even if the revoked device was compromised, this newest PUK is still confidential. For personal
storage, staleness is not an issue, as any device trying to encrypt data will first rotate the
per-user keys. But if other users are encrypting data for a compromised PUK and the server
cooperates, data could be readable by a revoked device.

This link is signed by the device that is rotating the PUK.

\subsubsection{Email Sigchains}

Users can change their email over time. It is important that at any specific point in time, each email corresponds to a unique user, so that Zoom users can be unequivocally identified. Also,
users should be able to audit whether at any point their email has been associated with another
user. We record the mapping between an email and the corresponding {\userID}s in an email sigchain.
These sigchains only have one kind of link, \textsf{UserIDChange}.

\begin{Verbatim}
{
  "sigchainType": "Email",
  "linkType": "UserIDChange",
  ...
  "email": COMMIT("alice@example.com"),

  "userIDChange": COMMIT({
    "userID": "ebc03d...",
    "userChainSequenceNumber": 9
   })
}
\end{Verbatim}

The \textsf{userChainSequenceNumber} refers to the position in the user sigchain of the corresponding
\textsf{EmailChange} link (or the initial \textsf{DeviceAdd} link).

Since users can change their email on the Zoom website, this link does not require any signatures.

\subsubsection{Account Sigchains}

Account sigchains consists of two kinds of links, which record the identity provider and ADN that
each account is using. \textsf{IDPUpdate} links contain the domain name of the \idp (say
\texttt{examplecorp.generic-idp.com}). {\idp}s should not use the same domain for multiple accounts to prevent equivocation of their attestations.

\begin{Verbatim}
{
  "sigchainType": "Account",
  "linkType": "IDPUpdate",
  ...
  "accountID": "abef02...",

  "idpDomain": "examplecorp.generic-idp.com"
}
\end{Verbatim}

\textsf{ADNChange} links associate an ADN with the account. Only the latest \textsf{ADNChange} link
is considered valid, and each one corresponds to an \textsf{AccountIDChange} link in the appropriate
ADN sigchain. If an account is no longer using an ADN, the \textsf{adnChange} section specifies ADN
\texttt{null} and the other field is omitted.

\begin{Verbatim}
{
  "sigchainType": "Account",
  "linkType": "ADNChange",
  ...
  "accountID": "abef02...",

  "adnChange": COMMIT({
    "adn": "example.org",
    "adnChainSequenceNumber": 9
  })
}
\end{Verbatim}

Links in account sigchains do not require any signatures.

\subsubsection{ADN Sigchains}

ADN sigchains track which \accountID a specific Account Domain Name is associated with. There is
only one type of link, \textsf{AccountIDChange}, which corresponds to and points to an
\textsf{ADNChange} link in the account sigchain for the appropriate \accountID:

\begin{Verbatim}
{
  "sigchainType": "ADN",
  "linkType": "AccountIDChange",
  ...
  "adn": "example.org",

  "accountIDChange": COMMIT({
    "accountID": "873c34...",
    "accountChainSequenceNumber": 29
  })
}
\end{Verbatim}

Links in ADN sigchains do not require any signatures.

\subsubsection{Membership Sigchains}

Membership sigchains record changes to the set of users which are part of each account. They
have a single type of link, \textsf{ChangeMembers}:

\begin{Verbatim}
{
  "sigchainType": "Membership",
  "linkType": "ChangeMembers",
  ...
  "accountID": "19aebb...",

  "added": [
    COMMIT({
      "userID": "db2f1c...",
      "userChainSequenceNumber": 9,
    }),
    ...
  ],
  "removed": [
    COMMIT({
      "userID": "9ae3d2...",
      "userChainSequenceNumber": 4
    }),
    ...
  ]
}
\end{Verbatim}

Each link can add or remove multiple users. Each user is hidden behind a commitment so that it is
possible to prove that an individual user is part of an account without also leaking the {\userID}s
of the other members that are being added as part of the same link. Hiding the {\userID}s of the
users being removed from the account would potentially make it harder to prove that a user is indeed
still a member of a specific account without opening all the commitments. We will solve this problem
in Phase III by leveraging the transparency layer, but until then, clients will not rely on
these sigchains, although the server will start keeping track of them.

Links in membership sigchains do not require any signatures.

\subsection{Highlighting Untrusted Devices with Contact Sync}
\label{subsec:contactsync}

Even with a strong concept of identity, impersonation attacks are still possible in meetings. If
Bob's coworker, Alice, has the email \texttt{alice@company.org}, Bob might not realize if he joins a
meeting with an impersonator using \texttt{al1ce@company.org}, especially if the impersonator has
their video turned off. Or if a hacker stole Alice's username and password, they could provision a
new device and pretend to be Alice. We'd like to have a TOFU-style UI feature to let Bob know if
it's the first time he's seeing a device in a meeting---but we also don't want to bother Bob for his
first meeting with Alice on every new device that Alice makes, which could lead to alert fatigue.
Specifically, we want to provide warnings when Bob is in a meeting with a device that is not
approved by a device that Bob has seen before. We'd also like Bob to share his meeting history
between his devices securely so they all have the latest information.

Each device maintains, for every other user that it has been in a meeting with, a record containing
that user's user sigchain tail, the time of their first meeting together, and the total number of
E2EE meetings they were in together. These records are updated after each meeting as appropriate,
though they are only updated when either
\begin{enumerate}
\item The meeting has less than 25 participants and the device has been in the meeting with the participant for over 10 minutes
\item The participant has been speaking for over 30 seconds
\end{enumerate}

In order for the meeting history to be shared across devices, clients periodically send encrypted meeting records to the server. Records are individually encrypted with the latest PUK, signed with the device key, and tagged with $t = \mathsf{HMAC}(k, \userID)$, where $k$ is a key derived from the PUK. The server stores a mapping between $(\deviceid, t)$ and the encrypted record, which the clients can update as necessary. When the client learns of a new PUK, records and tags are updated to use the new PUK lazily.

The records are encrypted to minimize the privacy loss in case they are leaked (Zoom servers already learn who is participating in which meeting). Because the tag is generated deterministically, these records would reveal if two of Alice's devices had meetings with the same user (but not which user), given that both devices used the same per-user key. However, we find this tradeoff acceptable as it allows for a more efficient synchronization.
Further, the server has the ability to rollback a device's record at any time, but doing so could only cause additional warnings.

When joining a meeting, clients generate tags for each other participant using each known PUK
and request the server to send any corresponding records. Any record signed by a revoked device is not considered. Given this data, we can provide warnings for
each device in a meeting:
\begin{enumerate}
\item If the device has been seen before, or if the device is trusted by a device that has been seen
    before as indicated by the trust graph, display the number of meetings with this user in the
    last month.
\item Otherwise, if the device is untrusted but the user has been seen before, display ``This is the
    first time you are talking to this device of this person."
\item Otherwise, display ``This is the first time you are talking to this person."
\end{enumerate}

Note that devices may not have access to all the per-user keys used to encrypt records, which could
result in extraneous warnings. For example, imagine Alice provisions Zoom on her phone and has a
meeting with Bob. Then, Alice provisions Zoom on her laptop and has another meeting with Bob without
approving the laptop from the phone. In this case, Alice's laptop does not have the PUK used by
Alice's phone to encrypt the record, so there will be another warning for Bob in the second meeting.

\subsection{Attesting Users' Identities through External Identity Providers}

Accounts that have an ADN and an identity provider (\idp) that supports our extension of the OIDC
protocol will be able to have the \idp vouch for the identity of their users in a way that other
meeting participants can independently verify. This mechanism restricts the ability, even for Zoom
insiders, to impersonate account members. Many organizations already trust an \idp for
authentication purposes, so this feature does not increase the attack surface or require additional
trust in the \idp.

In order for clients to be able to verify identity attestations by an external \idp, we need two
components:

\begin{enumerate}
\item A way for clients to determine the \idp associated with a Zoom account (that cannot be
    tampered with by the Zoom servers)
\item A mechanism for {\idp}s to issue---and for clients to verify---a signed attestation that binds
    a user's email address to their set of devices and keys
\end{enumerate}

\subsubsection{Associating Accounts with Identity Providers}
\label{subsec:adnToIdp}
In order to associate an account to its \idp, we will rely on TLS\@. Accounts with ADNs will
host a JSON object at the root of the subdomain \texttt{idp-config.well-known.} of
the ADN, e.g., \texttt{https://idp-config.well-known.example.org}.

The JSON object contains a field with key \texttt{us.zoom.idp.<CLOUD\_NAME>} whose value points to the unique domain
that the \idp has reserved for this account. For example, if \texttt{example.org} is using \texttt{generic-idp.com} as
their identity provider and has an account hosted on the Zoom commercial cloud, the object might look like:

\begin{Verbatim}
{
    "us.zoom.idp.commercial": "examplecorp.generic-idp.com"
}
\end{Verbatim}

Specifying the cloud in the field name allows to support ADNs configuring different IDPs for different clouds. Note that
since accounts are expected to change their \idp rarely, clients can cache this mapping aggressively.

If the endpoint does not return a valid response, clients will assume there is no \idp and not
display any identifiers for this user. Because Zoom will proxy client connections to ADNs to avoid
leaking the IP addresses of Zoom clients to external parties, a malicious Zoom server (or network
attackers) can convince clients that a certain account is not using an \idp by e.g., returning a
timeout error or a DNS NXDOMAIN message. We believe that this is the right tradeoff for the
following reasons:

\begin{enumerate}
\item Configuring the \idp via subdomains offers flexibility for the account admins. For example,
    the account admin can delegate the \texttt{idp-config.well-known} subdomain to the \idp, which
    can obtain a TLS certificate for the subdomain and host the required JSON file. The only
    technical action required by the account admin would be adding a DNS record for the
    subdomain.
\item In Phase III, our transparency layer will ensure that if the server tampers with an account’s
    ADN or \idp, the misbehavior will be detected through auditing of the account and ADN sigchains.
\end{enumerate}

\subsubsection{IDP Attestations}

\idp attestations will be generated and verified according to the OpenID Connect (OIDC) protocol.
OIDC is an extension of the widely used OAuth 2.0 authentication protocol, an industry standard that
many {\idp}s and Single Sign-On providers already support. OIDC provides a standardized format, the
ID token, to express claims about identities and their attributes. It also specifies how users can
request attestations for their own identity and verify ones obtained from other users.

We will customize the protocol by

\begin{enumerate}
\item Introducing an additional attribute \texttt{"zoom-identity-snapshot"} to the ID token in order
    to encode the state of a user’s identity on Zoom. {\idp}s will keep track of the latest value of
    this attribute for every account user.
\item Specifying how this attribute can only be updated by the authorized user, and not by any other
    user or entity, including Zoom servers.
\item Specifying how ID tokens about a specific user identity can be validated by other users.
\end{enumerate}

Our modified OIDC ID token (which will also be referred to as an \idp attestation) is a signed JSON
Web Token (JWT) data structure which contains claims about a user’s Zoom identity. The payload might
look like the following:

\begin{Verbatim}
{
  "iss": "https://examplecorp.generic-idp.com", // issuer

  "name": "Alice Henderson", // optional
  "email": "alice@example.com", // optional

  "zoom-identity-snapshot": "409788…",

  "exp": 1311281970 // expiration time
  "iat": 1311280970, // issue time

  [...]
}
\end{Verbatim}

The token contains an issuer field which identifies the OIDC issuer of the token (the \idp). In
order for Zoom clients to accept an identity claim, the issuer field must match the domain that
associates the \idp with the account (in our example, as returned by
\texttt{https://example.org/.well-known/idp-config}). \texttt{name} and \texttt{email} are marked as
optional to allow users to certify that they are part of a specific account without disclosing
exactly which member they are. \texttt{iat} and \texttt{exp} define the validity of the token.

The \texttt{zoom-identity-snapshot} field encodes the state of a user’s identity. As explained in
Section~\ref{subsec:sigchains}, clients keep track of these states using sigchains. An identity
snapshot will encode the user sigchain tail (which itself commits to the \userID); however, the identity provider can treat
this attribute as an opaque string and does not need to check its validity.

\subsubsection{Updating Snapshots}

Users who successfully sign into Zoom using OAuth 2.0 receive an access token from the \idp which
can be used to access protected resources. This access token will also be used to read and update
their own \texttt{zoom-identity-snapshot} attribute. To ensure that only an authorized user on a
Zoom native client is able to update the identity snapshot stored by the \idp, the Identity Snapshot
protocol requires {\idp}s to:

\begin{enumerate}
\item Introduce a new OAuth scope \texttt{update-zoom-identity} which is required to update the
    snapshot.
\item Only issue access tokens with the \texttt{update-zoom-identity} scope for requests that use
    PKCE and have set the redirect URI to a fixed custom URI intended to refer to the native Zoom
    desktop and mobile applications: \texttt{us.zoom://idp\_auth}.
\end{enumerate}

With the custom URI redirect, we trust the operating system and browser to redirect to the native
Zoom app and not to a website in a browser: such a website might be serving malicious JavaScript
from a compromised web server that could hijack the authorization flow. PKCE is an OAuth 2.0
extension that prevents other apps installed on the user's device from intercepting the
authorization code. The Zoom app will not share the resulting ``write" access token with anyone
else, including the Zoom server, but read-only access to snapshots can be extended to all access
tokens, including those issued to browser sessions.

We realize that the protections given to write ID tokens depend on the security of the underlying
platform including the user’s browser, their OS and their hardware, but we intend these protections to be
best effort measures.

Whenever devices make updates to their user sigchain, they submit the latest sigchain tail to their
\idp. In the event where a device successfully makes a sigchain update with the Zoom server but
fails to update the \idp, the next device that comes online will notice the new sigchain links and
update the \idp itself, but only after the user has reviewed the new links for potentially malicious
device additions.

\subsubsection{Validating IDP Attestations}

\idp attestations can be validated like standard OIDC ID tokens in the Authorization Code
Flow~\cite{oidc} with a few modifications. Users will:

\begin{enumerate}
\item Verify that the \idp in the \texttt{iss} field of the JWT matches the JSON hosted at the ADN's
    \texttt{idp-config.well-known.} subdomain. This ensures that the IDP is authorized to sign on
    behalf of the account ADN (as specified in Section~\ref{subsec:adnToIdp}).
\item Use OpenID Connect Discovery (e.g., make a request to \\
    \texttt{https://examplecorp.generic-idp.com/.well-known/openid-configuration}) \\ to ensure that the key
    used to sign the JWT is valid.
\item Validate the JWT, including checking its signature and expiration date.
\item Validate that the email and snapshot match the user sigchain provided by the Zoom server. When
    in-meeting, users will accept attestations that do not cover the latest sigchain tail as long as
    the new links since the {\idp}'s snapshot do not revoke the device currently being used in
    the meeting. If the new links change the user's email or account, then the user will be
    shown without identifiers.
\end{enumerate}

Note that the fetched attestation may be shared with and validated by anyone, so it doesn't include
the \texttt{aud} field.

\subsection{Changes to the Client}
\label{subsec:clientchanges}

Phase II includes new UI features as well as changes to client behavior during meetings.

\subsubsection{Device Management Changes}

Device management is now backed by the user’s sigchain. Upon visiting the device list, clients will
ask the Zoom server for the latest sigchain tail and process any new links in order to make sure
that the view is up-to-date. The device list will indicate active devices (which can be used to join
E2EE meetings) and revoked devices (which can no longer be used). It may also contain devices added
prior to Phase II that are not represented in the sigchain. Users will be able to revoke devices
from this view. If a device realizes that it is revoked (either via a server-trust notification or
by playing back its own sigchain), it will delete all private ephemeral and long-term keys as well
as sensitive data, then log itself out.

When provisioning Zoom on a new device, users review the device list and mark any that are
unrecognized, lost, stolen, or no longer used. Such devices are revoked at the same time the new
device is added to the sigchain.

After provisioning a new device, users get notifications on their old devices asking them to approve
or revoke any new untrusted devices. This list might include devices that are already revoked but
are still new from the perspective of the old device. Users also get notifications regarding changes made to their email address or account.

These notifications are powered by the sigchain, so the Zoom server does not have the ability to
suppress them in order to hide a malicious device addition or email change.

\subsubsection{Changes to Meeting Join/Leave Flow}

When joining a meeting, devices use the device key specified in their user sigchain as the long-term
signing key $\ivk_i$ for the protocol. The server signature as described in
Section~\ref{subsubsec:servercert} now also includes the sigchain tails for the corresponding user, email, account, and ADN sigchains.

In the ``Participant Key Generation'' procedure of Section~\ref{subsubsec:partikeygen}, the signed
$\binding_i$ will be extended to include the corresponding user, email, account, and ADN sigchains. This ensures that the server
cannot equivocate the user’s own account. If the account uses an \idp, the client will fetch and
include an attestation from the \idp in the binding as well.

In a meeting, Alice's client verifies Bob's sigchains and \idp attestation (if applicable) before
Alice's client displays identifiers for Bob in the UI. To do so, Alice's client fetches Bob's user
sigchain (which includes $\ivk_i$), email sigchain, account sigchain, ADN sigchain, and \idp
attestation. Alice's client verifies the server signature of the binding, checks that Bob's latest
sigchain is consistent with any previous retrievals of Bob's sigchain, and verifies the \idp
attestation by connecting to the ADN and verifying the \idp signature. Meeting participants'
clients may perform these checks asynchronously during a meeting, but the meeting may be configured
to require that the host completes this verification before the host performs the key exchange with a
joining participant. For example, requiring this verification before key exchange can help increase
the security of meetings that are restricted to users in specified accounts. Details about changes
to how users' identities are displayed in the meeting room, participant list, and waiting room are
described in Sections~\ref{subsec:displayid} and \ref{subsec:contactsync}.

The Zoom server will provide access control to ensure that sigchains are visible to other meeting
participants only for a short duration after a meeting begins. If Alice has never been
in a meeting with Charlie, Charlie will have no information regarding Alice's sigchain's contents,
length, or update frequency.

\subsection{Security Properties}

Users in accounts with an \idp that supports our protocol receive particularly strong security
guarantees. Because clients rely the account's ADN (and not the Zoom server) to determine the \idp,
a Zoom insider cannot impersonate these users unless the \idp or TLS itself is compromised. The Zoom
proxy or network attackers can potentially trick a user into believing that another user's account's
ADN does not have an associated \idp, but in this case, the user will appear without an email
address or ADN.

For all users, including those without an \idp or those whose \idp has been compromised, previous
meeting partners get Contact Sync warnings regarding new, potentially malicious devices.

The Zoom server cannot force devices to forget identity updates like device revocations: when
receiving sigchains, devices make sure the server cannot ``rollback" a sigchain to a previous point
in time.

In addition to the identifiers displayed in the user interface, our solution provides some limited
extra information about a user to their
meeting participants: the sigchains reveal the history of the user's devices, including when they
were added and revoked (but not their names, which are protected behind a commitment). Similarly,
the number of times that a user changes their email address or account is visible (but not the
previous emails or account IDs). Moreover, since sigchain statements are timestamped, time
correlations between different statements might be exploited to infer, for example, that two users
swapped their email addresses. While this information will not be displayed to the meeting
participants by the Zoom app, the client needs this data to perform the sigchain validation and
therefore a motivated attacker might extract such information. We believe that this is acceptable;
it is similar to the security code change warnings in applications like
Signal and WhatsApp. Note that sigchains are not publicly available: they are provided as needed to other meeting participants during the meeting. Even if Alice meets with Bob on one day, the Zoom server will not tell Bob about any updates to Alice's sigchain afterwards until they are in a meeting again.

We stress that seeing a specific user identity in the participant list of a meeting does not imply
that the corresponding user has chosen to participate in the meeting or is still actively
participating, but only that that user could potentially have access to the encrypted meeting
contents. A malicious insider could either trick the leader into including a user in the participant
list (when the user is not actually present in the meeting), or hide the fact that a participant has
left a meeting (so that other users are convinced they are still participating). All such
participants would still trigger Contact Sync warnings as detailed in
Section~\ref{subsec:contactsync}, and clients will remember their identities for future meetings. We
believe that preventing these issues would add too much complexity and overhead to the protocol.

\subsection{Areas to Improve in Phase II}

While Phase II provides significantly stronger security guarantees compared to Phase I, there are
still attacks it won't be able to prevent.

Though Contact Sync warnings improve Zoom users' security, alert fatigue can make the warnings less
useful. If meeting partners regularly fail to approve new devices with earlier ones, or if the
server does not properly sync meeting records, users can grow accustomed to the warnings and possibly
ignore them in the event of a real attack. Even without an attack, excessive warnings make for a
suboptimal and tiresome user experience.

While devices ensure that the server cannot rollback a sigchain that the device has seen before,
this doesn't prevent ``forks" of sigchains across different devices. For example, a compromised
server, in order to impersonate Bob, could add a fake device to Bob's sigchain when Alice requests
it at the start of a meeting. When Bob requests his own sigchain to view his device list, the server
removes the device addition link so Bob doesn't see the malicious device. If Alice and Bob later
join a video meeting, this forking attack would be revealed as users sign over their view of the
sigchain tail, but such a meeting is not guaranteed to occur.

Because of the potential for forking attacks in Phase II, we are unable to offer users in accounts
without {\idp}s the ability to display their email address and ADNs in meetings, and we don't offer
account admins the ability to exhaustively audit which users are in their account.

In Phase III, we'll introduce a transparency layer that will address these shortcomings.
